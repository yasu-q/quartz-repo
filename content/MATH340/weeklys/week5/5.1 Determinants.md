![vid](https://www.youtube.com/watch?v=_1PtPKcVMs4&ab_channel=MathCoursesbyDr.Ebrahimian)
Also check out the relevant [3blue1brown vid](https://www.youtube.com/watch?v=Ip3X9LOh2dk&ab_channel=3Blue1Brown)

What we are trying to define
"In this section we would like to define the determinant of a square matrix. One interpretation of determinant is “volume”. Given $n$ vectors ${\bf v}_1, . . . , {\bf v}_n ∈ \mathbb{R}^n$, we want the $n × n$ determinant corresponding to ${\bf v}_1, . . . , {\bf v}_n$ to determine the volume of the parallelepiped determined by these $n$ vectors. We expect any reasonable volume to satisfy the following properties"

![[Pasted image 20240922224018.png]]

1. If the vectors are aligned, then the volume (or whatever equivalent in the dimension) should be zero. (the thing collapses to nothing) **(Alternating)**
2. Um, check the video idfk **(Additivity)**
3. Multiplying a determinant by a scalar should be the same thing as multiplying one of the inputs by the same scalar **(Alternating)**
## 5.1 Multi linearity
Let $D : M_n(\mathbb{R}) \rightarrow \mathbb{R}$ be a function. (the domain is a square $n \times n$ matrix of real numbers)

We say $D$ is multi-linear if $D$ is linear with respect to each row. In other words, for every $i$ we have the following
$$
D
\begin{pmatrix}
	{\bf v}_1 \\
	\vdots \\
	a{\bf v}_i + b{\bf w} \\
	\vdots \\
	{\bf v}_n
\end{pmatrix}
=
aD
\begin{pmatrix}
	{\bf v}_1 \\
	\vdots \\
	{\bf v}_i \\
	\vdots \\
	{\bf v}_n
\end{pmatrix}
+bD
\begin{pmatrix}
	{\bf v}_1 \\
	\vdots \\
	{w} \\
	\vdots \\
	{\bf v}_n
\end{pmatrix}
\leftarrow i-\text{th row}
$$
We say $D$ is alternating if 
$$
D 
\begin{pmatrix}
	{\bf v}_1 \\
	\vdots \\
	{\bf v}_n
\end{pmatrix}
=0
$$
when ${\bf v}_i = {\bf v}_j$ for some $i \neq j$. When one of the rows is the same as a another. WLOG

we write $D({\bf v}, \dots, {\bf v}_n)$ inserting commas to indicate ${\bf v}_1, \dots, {\bf v}_n$ are rows and not columns.
***
## Example 5.1
For an alternating and linear $D$ and a $2 \times 2$ matrix, demonstrate the following:
$$
D({\bf u}, {\bf v}) = -D({\bf v}, {\bf u})
$$
Consider the following
$$
D({\bf u} + {\bf v}, {\bf u}, {\bf v}) \xRightarrow{Alternating} 0
$$
Now apply the following
$$
D({\bf u} + {\bf v}, {\bf u} + {\bf v}) = D({\bf u} + {\bf v}, {\bf u}) + D({\bf u} + {\bf v}, {\bf v})
$$
$$
\Rightarrow
D({\bf u}, {\bf u}) + D({\bf v}, {\bf u}) + D({\bf u}, {\bf v}) + D({\bf v},{\bf v}) = 0 + D({\bf v}, {\bf u}) + D({\bf u}, {\bf v}) + 0 = 0
$$
$$
\Rightarrow
D({\bf v}, {\bf u}) = -D({\bf u}, {\bf v})
$$
## Example 5.2
Essentially, we derive what a $2 \times 2$ determinant should look like
$$
D
\begin{pmatrix}
	a & b \\
	c & d
\end{pmatrix}
=
ad -bc
$$
***
## Theorem 5.1
Let $D : M_n(\mathbb{R}) → R$ be alternating and multi-linear, then it satisfies the following properties.

1. Swapping two rows, negates D. In other words,
$$
D({\bf v}_1, \dots, {\bf v}_i, \dots, {\bf v}_j, \dots, {\bf v}_n) = -D({\bf v}_1, \dots, {\bf v}_j, \dots, {\bf v}_i, \dots, {\bf v}_n)
$$

2. Scaling a row by $c$ scales $D$. In other words,
$$
D({\bf v}_1, \dots, c{\bf v}_i, \dots, {\bf v}_n) = cD({\bf v}_1, \dots, {\bf v}_j, \dots, {\bf v}_n)
$$

3. Adding a multiple of one two to a different row does not change $D$. In other words
$$
D({\bf v}_1, \dots, {\bf v}_i + c{\bf v}_j, \dotsm {\bf v}_n) = D({\bf v}_1, \dots, {\bf v}_i + c{\bf v}_j, \dotsm {\bf v}_n) \text{ for } i \neq j
$$

4. $D({\bf v}, \dots, {\bf v}_n) = 0$ if ${\bf v}_1, \dots, {\bf v}_n$ are linearly dependent. 

Basically, the vectors align at some point so they collapse a dimension and make the '''volume''' zero

Clearly, the first three operations are very familiar. These are precisely the row operations that we explored when solving systems of linear equations (??)
## Theorem 5.2 
For every positive integer $n$, there is a unique multi-linear, alternating function 
$D : M_n(\mathbb{R}) → R$ satisfying $D(I) = 1$. ($I$ is the [[Identity matrix]]). I.e. the determinant function equation will be unique for each size of matrix

This function is in the form:
$$
D
\begin{pmatrix}
a_{11} & \cdots & a_{1n} \\
& \vdots \\
a_{n1} & \cdots & a_{nn}
\end{pmatrix}
=
\sum \text{sgn}(\alpha)a_{1 \alpha(1)} \cdots a_{n\alpha(n)}
$$
Where $\alpha$ is a permutation of $1, \cdots, n$ (???). This is the general form of a determinant for
a $n \times n$ matrix.

OR

![[Pasted image 20240924202231.png]]

or check [this video](https://www.youtube.com/watch?v=H9BWRYJNIv4&ab_channel=KhanAcademy) out. idfk tbh
## 5.2 Determinant
Let $D$ be a the function in the above theorem. Then the determinant of an $n \times n$ matrix $A$ whose rows are ${\bf v}_1, \cdots, {\bf v}_n$ is defined as $D({\bf v}_1, \cdots, {\bf v}_n)$ and is denoted by $\det A$ or $\det (A)$  
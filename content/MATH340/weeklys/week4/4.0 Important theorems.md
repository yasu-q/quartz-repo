from [[4.1 Norms]]
## 4.1 Norm
A norm on $\mathbb{R}^n$ is a function that assigns to any vector $\vec{v} \in \mathbb{R}^n$ a nonnegative real number $||\vec{v}||$ that satisfies all of the following:

1. $||\vec{v}|| \gt 0$ for every non zero $\vec{v} \in \mathbb{R}^n$ (Positivity)

2. $||\vec{v} + \vec{w}|| \leq ||\vec{v}|| + ||\vec{w}||$ for every $\vec{v}, \vec{w} \in \mathbb{R}^n$ (Triangle Inequality)

3. $||c\vec{v}|| = |c| \space ||\vec{v}||$ for every $\vec{v} \in \mathbb{R}^n$ and $c \in \mathbb{R}$ (Homogeneity)

The following theorem connect the notion of norms and inner products:
## Theorem 4.1
If ⟨, ⟩ is an inner product on $\mathbb{R}^n$, then the function defined by $||\vec{v}|| = \sqrt{⟨\vec{v}, \vec{v}⟩}$ is a norm

![[Pasted image 20240916215336.png]]

When a specific norm is not mentioned, we standard Euclidean norm is utilized (dot product)

from [[4.2 Linear transformations and matrix operations]]
## Theorem 4.2
 Let $L : V → W$ be a function between vector spaces. Then, the following are equivalent

1. $L$ is linear

2. $L(\vec{u} + c\vec{v}) = L(\vec{u}) + cL(\vec{v})$ for all $\vec{u}, \vec{v} \in V$ and all $c \in \mathbb{R}^n$

3. $L(a\vec{u} + b\vec{v}) = aL(\vec{u}) + bL(\vec{v})$ for all $\vec{u}, \vec{v} \in V$ and all $c \in \mathbb{R}^n$

from [[4.3 Kernel and image]]
## Theorem 4.8
Suppose $L : \mathbb{R}^n → \mathbb{R}^m$ is a linear transformation whose matrix in the standard basis is $A$. Then,

1. Im $L = \text{Col} (A)$ 

2. Ker $L = (\text{Row}(A))^\perp$

3. dim Ker $L$ + dim Im $L$ = $n$
## Theorem 4.9 Rank-Nullity 
Let $V$ and $W$ be a vector subspaces, and $L : V \rightarrow W$ be a linear Transformation. Then,
$$
\dim\text{Ker } L + \dim\text{Im} L = \dim V
$$
Yes, this is basically the same thing as (3)

Also, if a linear function is bijective then its image is equal to its codomain
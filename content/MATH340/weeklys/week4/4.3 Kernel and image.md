 ![video](https://www.youtube.com/watch?v=pmU5t_1G1g8&list=PLciPFwfwQdT9QD6P62J6xBbrs2yJFP3RF&index=17&ab_channel=MathCoursesbyDr.Ebrahimian)
## 4.8 Kernel of a linear transformation
Given a linear transformation $L : V \rightarrow W$, the kernel of $L$ is defined as $\ker L = L^{-1}(\{0\})$ or in the other words:
$$
\ker L = \{\vec{w} \in W | L(v) = \bf0\}
$$
The image (or range) or $L$ is defined as 
$$
\text{Im } L = \{\vec{w} \in W | \vec{w} = L(v) \text{ for some } \vec{v} \in V\}
$$
I.e. the 'real' outputs of $L$.
Basically the same as previous definitions of kernel in [[3.2 Pivot analysis]] and image in [[1.2 Functions]]. $L$ is a linear function, so image makes sense. It also has a matrix associated with it, which is why kernel is involved.
## Theorem 4.6 
Let $L : V → W$ be a linear transformation of vector spaces. Then Ker $L$ is a subspace of $V$ and Im $L$ is a subspace of $W$.

![[Pasted image 20240921150649.png]]

*Note that if a function is not linear there is no guarantee that its image will be a subspace. However, with linear functions it is guaranteed that its image will be a valid subspace*

Check out video to understand how these are found
## Theorem 4.7
Suppose $L : V → W$ is a linear transformation of vector spaces. Then, Ker $L = {\bf 0}$ if and only if $L$ is one-to-one (see definition in [[1.2 Functions]]). If $L$ is one-to-one, then dim Im $L$ = dim $V$ i.e. the image is the entire domain.
## Theorem 4.8
Suppose $L : \mathbb{R}^n → \mathbb{R}^m$ is a linear transformation whose matrix in the standard basis is $A$. Then,

1. Im $L = \text{Col} (A)$ 

2. Ker $L = (\text{Row}(A))^\perp$

3. dim Ker $L$ + dim Im $L$ = $n$
## Theorem 4.9 Rank-Nullity 
Let $V$ and $W$ be a vector subspaces, and $L : V \rightarrow W$ be a linear Transformation. Then,
$$
\dim\text{Ker } L + \dim\text{Im} L = \dim V
$$
Yes, this is basically the same thing as (3)

Also, if a linear function is bijective then its image is equal to its codomain
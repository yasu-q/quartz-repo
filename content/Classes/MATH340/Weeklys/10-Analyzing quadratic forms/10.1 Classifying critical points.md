The Second Partials Test ([[9.1 Critical points in R2]]) for a function $f : \mathbb{R}^2 → \mathbb{R}$ allows us to determine if a critical point is a local minimum, a local maximum, or a saddle point. Now, we will turn our focus to n variable real-valued functions. Similar to what we did in the 2-dimensional case, we start with studying quadratic forms ([[9.1 Critical points in R2]])
## 10.1 Symmetric matrices
A matrix $A$ is called symmetric if $A^T = A$. In other words, the $(i, j)$ entry of $A$ is the same as its $(j, i)$ entry for all $i, j$

![[Pasted image 20241028191248.png]]

Diagonals are equal
## Theorem 10.1
Any quadratic form $q : \mathbb{R}^n → \mathbb{R}$ can be written as $q({\bf x}) = {\bf x}^T A{\bf x}$, where $A ∈ M_n(\mathbb{R})$ is symmetric and ${\bf x} ∈ \mathbb{R}^n$ is a column vector. Furthermore, given $q$, this symmetric matrix $A$ is unique. Note that in the theorem above if $q(x_1, . . . , x_n) = \sum\limits_{1≤i≤j≤n} a_{ij} x_ix_j$  then the $(i, j)$ entry of $A$ is $a_{ij} /2$ or $a_{ji}/2$ depending on whether $i < j$ or $j < i$, and the $(i, i)$ entry of A is $a_{ii}$

i.e. any quadratic form can be written in the form
$$
q({\bf x}) = {\bf x}^T A{\bf x}
$$
![[Pasted image 20241028191639.png]]

Extend this to $\mathbb{R}^n$ baddabingbaddboom
***
## Example 10.1
Find the matrix associated with the quadratic form
$$
g(x,y,z) = x^2 + 2y^2- z^2 + 3xy + xz - yz
$$
Refer to the diagram above. Remember that this matrix should be symmetric. This gives the following matrix
$$
A = 
\begin{pmatrix}
	1 & \frac{3}{2} & \frac{1}{2} \\
	\frac{3}{2} & 2 & -\frac{1}{2} \\
	\frac{1}{2} & -\frac{1}{2} & -1
\end{pmatrix}
$$
***
## 10.2 Matrix of a quadratic form
Given a symmetric $n×n$ matrix $A$ the quadratic form $q({\bf x}) = {\bf x}^T A{\bf x}$ is called the quadratic form associated with $A$. We also say $A$ is the matrix associated with $q$

Note that ${\bf 0}$ is a critical point of $q$. Also, for a quadratic form $q$, a scalar $c$, and a vector ${\bf x}$ we have $q(c{\bf x}) = c^2q({\bf x}$). Therefore, to determine if ${\bf 0}$ is a local minimum, local maximum or a saddle point, we need to determine the maximum and minimum of $q$ over the unit sphere given by $||{\bf x}|| = 1$. This can be done using the Lagrange Multipliers Theorem.
## Theorem 10.2
 A quadratic form q has a local minimum (resp. local maximum) at ${\bf 0}$ if and only if $q$ is positive semidefinite (resp. negative semidefinite). Similarly, $q$ has a saddle point at ${\bf 0}$ if and only if ${\bf q}$ is nondefinite
## Theorem 10.3
Let $q$ be a quadratic form associated with an $n × n$ symmetric matrix $A$. If ${\bf q}$ attains its maximum or minimum value on the unit sphere in $\mathbb{R}^n$ at a point ${\bf v}$ (with $||{\bf v}|| = 1$), then $A{\bf v} = λ{\bf v}$ for some $λ ∈ R$

i.e. ${\bf q}$'s maximum and minimums will be eigenvalues vectors of its matrix, and they will of course occur at eigen vectors on the unit sphere
## 10.3 Eigenvectors
Given a square matrix $A$, we say a nonzero vector ${\bf v}$ is an eigenvector of $A$ if there is $λ ∈ \mathbb{R}$ for which $A{\bf v} = λ{\bf v}$. The number $λ$ is called an eigenvalue of $A$, and the pair $(λ, {\bf v})$ is called an eigenpair of $A$.

Note that if $(λ, {\bf v})$ is an eigenpair of a matrix $A$ associated to a quadratic form $q$, then $q({\bf v})$ = $λ||{\bf v}||^2$

These are kind of a big deal in linear algebra

![vid](https://www.youtube.com/watch?v=PFDu9oVAE-g&ab_channel=3Blue1Brown)
## Theorem 10.4
Given a quadratic form $q$ on $\mathbb{R}^n$, the maximum and minimum value of this quadratic form on the unit sphere $\{{\bf x} ∈ \mathbb{R}^n \,|\, ||{\bf x}|| = 1\}$ are the largest and smallest eigenvalues of the matrix $A$ associated with $q$.

[conversation with chatgpt about these concepts ](https://chatgpt.com/share/67201e45-7310-8005-8930-4b40818eff9e)
## Theorem 10.5
A real number $λ$ is an eigenvalue of a square matrix $A$ if and only if $\det(A − λI) = 0$, where $I$ is the identity matrix

[[Note about eigenvectors]]
### Corollary 10.1
Let $A$ be the matrix associated with a quadratic form $q$. Then, the maximum and minimum values of $q({\bf x})$ where ${\bf x}$ is on the unit sphere is the largest and smallest real root $λ$ of the equation $\det(A−λI) = 0$
***
## Example 10.2
Find the maximum and minimum values of the quadratic form
$$
q(x,y) = 3x^2 + 2y^2 - 2xy
$$
Subject to the condition 
$$
x^2+y^2 = 1
$$
First, find the matrix associated with the quadratic form. 
$$
A = 
\begin{pmatrix}
3 & -1 \\
-1 & 2
\end{pmatrix}
$$
Next, setup the equation
$$
\det(A - \lambda I) = 0
\,\,\,\, \Rightarrow \,\,\,\,
\det
\begin{pmatrix}
	3 - \lambda & -1 \\
	-1 & 2-\lambda
\end{pmatrix}
=0
$$
Take the determinant
$$
(3-\lambda)(2-\lambda) - (-1)^2 = 0
$$
$$
\Rightarrow \lambda^2 - 5\lambda + 5 = 0
$$
Which gets us the following values for lambda
$$
\lambda = \frac{5 \pm \sqrt{5}}{2}
$$
So the minimum is $-$ and the maximum is $+$
***
### Minor matrices and $\Delta$ determinants
Minor matrices are, in essence, sub square matrices of a larger square matrix. See [wikipedia](https://en.wikipedia.org/wiki/Minor_(linear_algebra)). For our purposes, we want to look the at minor matrices constructed by starting at the top left corner and expanding down diagonally right.

Consider a matrix
$$
A = 
\begin{pmatrix}
a & b & c \\
d & e & f \\
g & h & i
\end{pmatrix}
$$
The minor matrices (from the top left corner) are 
$$
(a)_{1}
\,\,\, \& \,\,\
\begin{pmatrix}
a & b \\
d & e
\end{pmatrix}_{2}
\,\,\, \& \,\,\
\begin{pmatrix}
a & b & c \\
d & e & f \\
g & h & i
\end{pmatrix}_3
$$

 Let $A$ be an $n × n$ matrix. For every $k ≤ n$ we denote the determinant of the upper left-hand $k × k$ submatrix of $A$ is denoted by $∆_k$
## 10.4 Positive definite matrices
 A symmetric matrix $A$ is called positive definite if the quadratic form $q({\bf x}) = {\bf x}^TA{\bf x}$ associated with $A$ is positive definite. Similarly we define a negative definite, nondefinite, positive semidefinite and negative semidefinite matrix
## Theorem 10.6
 Let $q({\bf x}) = {\bf x}^T A{\bf x}$ be a quadratic form where $A$ is symmetric
 
1. $q$ is positive definite (resp. positive semidefinite) if and only if all eigenvalues of $A$ are positive (resp. nonnegative)

2. $q$ is negative definite (resp. negative semidefinite) if and only if all eigenvalues of $A$ are negative (resp. nonpositive)

3.  $q$ is nondefinite if and only if it has both a positive and a negative eigenvalue
## Theorem 10.7
 Let $q({\bf x}) = {\bf x}^T A{\bf x}$ be a quadratic form where $A$ is symmetric

1. $q$ positive definite if and only if $∆_k > 0$ for all $k$

2. $q$ is negative definite if and only if $(−1)^k∆_k > 0$ for all $k$ (they alternate in sign

3. Assume $\det A \neq 0$. The quadratic form $q$ is nondefinite if and only if neither of the previous two conditions is satisfied
### Motivation for quadratic forms
Let $f$  be a real valued function $f:\mathbb{R}^n \rightarrow \mathbb{R}$
To classify a critical point a of a function $f$ we approximate the function $f$ with a quadratic form and then determine if this quadratic form is positive-definite, negative-definite, or nondefinite

**Reasoning**

Let ${\bf a}$ be a critical point of $f$ 
We can approximate the value of a function $f$ at a point ${\bf x}$ by utilizing the tangent plane approximation ([[8.2 Derivatives and differentials]])
$$
f({\bf x}) \approx f({\bf a}) + f'({\bf a})({\bf x} - {\bf a})
$$
This stems from the first degree Taylor series of $f$. We can further approximate this utilizing the 2nd degree Taylor series of $f$ 
$$
f({\bf x}) \approx f({\bf a}) + f'({\bf a})({\bf x} - {\bf a}) + \frac{1}{2}({\bf x} - {\bf a})^T H_f({\bf a})({\bf x} - {\bf a})
$$
Where $H_f$ is the hessian matrix (essentially the gradient of the gradient). If you are wondering how this is found, see how to calculate the 2nd derivative of a function like $f$. Notice how the 2nd degree term of this Taylor series is in the form of a quadratic form (see [[9.1 Critical points in R2]]).

Since ${\bf a}$ is a critical point, we know that the first degree of the Taylor polynomial will be equal to zero. Thus, if we can find the sign of the quadratic form, then we can determine whether ${\bf a}$ is a maximum of minimum (or neither if it is a saddle point) $f$ by looking at the sign of the quadratic form (so long as this error term is not zero) which will give bounds to the error of the approximation. 

Note we can ignore the higher degree terms in the Taylor because they become insignificant via the Lagrange remainder and [Taylor's theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem)

